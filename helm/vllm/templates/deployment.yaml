apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "vllm.fullname" . }}
  labels:
    {{- include "vllm.labels" . | nindent 4 }}
spec:
  replicas: 1
  selector:
    matchLabels:
      {{- include "vllm.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      labels:
        {{- include "vllm.selectorLabels" . | nindent 8 }}
      annotations:
        instrumentation.opentelemetry.io/inject-sdk: "true"
        instrumentation.opentelemetry.io/endpoint: {{ .Values.otel.endpoint | quote }}
    spec:
      runtimeClassName: {{ .Values.security.runtimeClassName | quote }}
      serviceAccountName: {{ include "vllm.serviceAccountName" . }}
      containers:
        - name: vllm
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          args:
            - "--port"
            - {{ .Values.service.port | quote }}
            - "--otlp-endpoint"
            - {{ .Values.otel.endpoint | quote }}
          ports:
            - containerPort: {{ .Values.service.port }}
              name: http
          resources:
            {{- toYaml .Values.resources | nindent 12 }}
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
      nodeSelector:
        nvidia.com/gpu.present: "true"
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule

